{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b961799c",
   "metadata": {},
   "source": [
    "# 1. Introduction\n",
    "# Breast Cancer Survival Analysis\n",
    "# METABRIC Dataset - Comprehensive Survival Analysis Pipeline\n",
    "\n",
    "## 1. Introduction and Clinical Objective\n",
    "\n",
    "### Clinical Context\n",
    "Breast cancer is the most common cancer among women worldwide. Survival analysis is critical for understanding patient prognosis, treatment effectiveness, and identifying risk factors associated with survival outcomes.\n",
    "\n",
    "### Dataset\n",
    "The METABRIC (Molecular Taxonomy of Breast Cancer International Consortium) dataset contains clinical and molecular data from breast cancer patients, including:\n",
    "- Clinical variables (age, tumor characteristics, treatment history)\n",
    "- Molecular subtypes (PAM50 classification)\n",
    "- Survival outcomes (overall survival and relapse-free survival)\n",
    "\n",
    "### Clinical Objectives\n",
    "1. **Prognostic Modeling**: Develop models to predict overall survival in breast cancer patients\n",
    "2. **Risk Stratification**: Identify patient subgroups with distinct survival patterns\n",
    "3. **Feature Importance**: Understand which clinical and molecular factors most strongly influence survival\n",
    "4. **Treatment Insights**: Evaluate associations between treatment modalities and survival outcomes\n",
    "\n",
    "### Outcome Definition\n",
    "- Overall Survival (OS)\n",
    "  - Duration: Time from diagnosis to death (in months)\n",
    "  - Event: Death from any cause (Deceased) or censoring (Living)\n",
    "  \n",
    "\n",
    "### Clinical Relevance\n",
    "- Help clinicians make informed treatment decisions\n",
    "- Enable personalized risk assessment\n",
    "- Support resource allocation and patient counseling\n",
    "- Provide insights for clinical trial design\n",
    "\n",
    "### Methods Overview\n",
    "- Survival analysis using Kaplan-Meier estimation for descriptive statistics\n",
    "- Cox proportional hazards models for multivariable analysis\n",
    "- Machine learning approaches (Decision Trees, Random Forests) for prediction\n",
    "- Group-aware splitting to ensure fair evaluation across patient subgroups\n",
    "- Leakage controls to prevent data leakage and ensure clinically meaningful predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8149fd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages if not already installed\n",
    "# Run this cell first if you get import errors\n",
    "\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "def install_package(package):\n",
    "    \"\"\"Install a package if not already installed\"\"\"\n",
    "    try:\n",
    "        __import__(package)\n",
    "        print(f\"✓ {package} is already installed\")\n",
    "    except ImportError:\n",
    "        print(f\"Installing {package}...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "        print(f\"✓ {package} installed successfully\")\n",
    "\n",
    "# Install required packages\n",
    "required_packages = [\"lifelines\", \"scikit-survival\"]\n",
    "for pkg in required_packages:\n",
    "    install_package(pkg)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Package installation check complete!\")\n",
    "print(\"=\"*60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65f0098",
   "metadata": {},
   "source": [
    "# 2. Setup and Reproducibility\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd762cf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ENVIRONMENT AND VERSION INFORMATION\n",
      "============================================================\n",
      "Python              : 3.12.4\n",
      "numpy               : 1.26.4\n",
      "pandas              : 2.2.3\n",
      "lifelines           : 0.30.0\n",
      "scikit-learn        : 1.6.1\n",
      "scikit-survival     : available\n",
      "Random State        : 42\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Setup and reproducibility\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# Survival modeling\n",
    "import lifelines\n",
    "from lifelines import KaplanMeierFitter, CoxPHFitter\n",
    "from lifelines.statistics import logrank_test\n",
    "from lifelines.utils import restricted_mean_survival_time\n",
    "\n",
    "# Scikit-learn core utilities\n",
    "import sklearn\n",
    "from sklearn import set_config\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit, GroupShuffleSplit\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score,\n",
    "    average_precision_score,\n",
    "    brier_score_loss,\n",
    "    roc_curve,\n",
    "    precision_recall_curve\n",
    ")\n",
    "\n",
    "# Optional scikit-survival for advanced metrics\n",
    "try:\n",
    "    from sksurv.metrics import cumulative_dynamic_auc, integrated_brier_score\n",
    "    from sksurv.util import Surv\n",
    "    SKSURV_AVAILABLE = True\n",
    "except ImportError:\n",
    "    print(\"scikit-survival not available. Some time-dependent metrics will be skipped.\")\n",
    "    SKSURV_AVAILABLE = False\n",
    "\n",
    "# Global configuration for reproducibility\n",
    "RANDOM_STATE = 42\n",
    "SEED = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "# Matplotlib defaults\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 6)\n",
    "plt.rcParams[\"axes.grid\"] = True\n",
    "plt.rcParams[\"font.size\"] = 11\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Display versions for reproducibility\n",
    "def _get_ver(mod):\n",
    "    return getattr(mod, \"__version__\", \"n/a\")\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"ENVIRONMENT AND VERSION INFORMATION\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Python              : {sys.version.split()[0]}\")\n",
    "print(f\"numpy               : {_get_ver(np)}\")\n",
    "print(f\"pandas              : {_get_ver(pd)}\")\n",
    "print(f\"lifelines           : {_get_ver(lifelines)}\")\n",
    "print(f\"scikit-learn        : {_get_ver(sklearn)}\")\n",
    "print(f\"scikit-survival     : {'available' if SKSURV_AVAILABLE else 'not available'}\")\n",
    "print(f\"Random State        : {RANDOM_STATE}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Pandas display options\n",
    "pd.set_option(\"display.max_columns\", 100)\n",
    "pd.set_option(\"display.width\", 120)\n",
    "pd.set_option(\"display.max_rows\", 50)\n",
    "\n",
    "# Set sklearn to return DataFrames where possible\n",
    "set_config(transform_output=\"pandas\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0b39c0",
   "metadata": {},
   "source": [
    "# 3. Load data and define survival variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3bdd59",
   "metadata": {},
   "source": [
    "## Dataset Description\n",
    "\n",
    "The dataset includes detailed clinical, molecular, and treatment-related information for breast cancer patients.  \n",
    "Below are the main columns and their descriptions:\n",
    "\n",
    "---\n",
    "\n",
    "### Common Columns\n",
    "\n",
    "- **Patient ID:** Unique patient identifier. *(Categorical variable)*\n",
    "- **Age at Diagnosis:** Age of the patient when first diagnosed with breast cancer. *(Numerical variable)*\n",
    "- **Type of Breast Surgery:** Type of breast surgery the patient underwent. *(Categorical variable)*\n",
    "- **Cancer Type:** General type of cancer. *(Categorical variable)*\n",
    "- **Cancer Type Detailed:** Histological subtype of the cancer. *(Categorical variable)*\n",
    "- **Cellularity:** Proportion of cancer within the residual tumor bed. *(Categorical variable)*\n",
    "- **Chemotherapy:** Indicates whether the patient received chemotherapy. *(Categorical variable)*\n",
    "- **Pam50 + Claudin-low subtype:** Molecular classification based on the PAM50 gene signature and Claudin-low subtype. *(Categorical variable)*\n",
    "- **Cohort:** Specific group or population of patients included in the study, often categorized by shared characteristics or treatment protocols. *(Numerical variable)*\n",
    "- **ER Status measured by IHC:** Estrogen receptor (ER) expression status measured by immunohistochemistry. *(Categorical variable)*\n",
    "- **ER Status:** Whether the tumor is positive or negative for estrogen receptors. *(Categorical variable)*\n",
    "- **Neoplasm Histologic Grade:** Grade of the tumor based on how abnormal cancer cells appear under a microscope (indicator of aggressiveness). *(Numerical variable)*\n",
    "- **HER2 status measured by SNP6:** HER2 receptor status measured using SNP6 technology. *(Categorical variable)*\n",
    "- **HER2 Status:** Whether HER2 receptors are overexpressed in the tumor (positive/negative). *(Categorical variable)*\n",
    "- **Tumor Other Histologic Subtype:** Additional histological classification of the tumor. *(Categorical variable)*\n",
    "- **Hormone Therapy:** Indicates whether the patient received hormone therapy. *(Categorical variable)*\n",
    "- **Inferred Menopausal State:** Patient’s menopausal status inferred from clinical data. *(Categorical variable)*\n",
    "- **Integrative Cluster:** Tumor classification based on integrative molecular analysis. *(Categorical variable)*\n",
    "- **Primary Tumor Laterality:** Side of the body (left/right breast) where the primary tumor is located. *(Categorical variable)*\n",
    "- **Lymph nodes examined positive:** Number of lymph nodes that tested positive for cancer. *(Numerical variable)*\n",
    "- **Mutation Count:** Total number of genetic mutations identified in the tumor. *(Numerical variable)*\n",
    "- **Nottingham Prognostic Index:** Prognostic score assessing breast cancer outcome based on tumor histology and clinical features. *(Numerical variable)*\n",
    "- **Oncotree Code:** Standardized code classifying tumor types according to the Oncotree system. *(Categorical variable)*\n",
    "- **PR Status:** Progesterone receptor status of the tumor (positive/negative). *(Categorical variable)*\n",
    "- **Radio Therapy:** Indicates whether the patient received radiation therapy. *(Categorical variable)*\n",
    "- **Sex:** Gender of the patient. *(Categorical variable)*\n",
    "- **3-Gene Classifier Subtype:** Tumor subtype based on the expression of three specific genes. *(Categorical variable)*\n",
    "- **Tumor Size:** Size of the tumor (in centimeters). *(Numerical variable)*\n",
    "- **Tumor Stage:** Stage of the tumor, representing the extent of cancer spread. *(Numerical variable)*\n",
    "\n",
    "---\n",
    "\n",
    "### Durations and Events (Survival Information)\n",
    "\n",
    "- **Patient's Vital Status:** Indicates whether the patient is alive or deceased. *(Categorical variable)*\n",
    "- **Relapse Free Status (Months):** Duration (in months) that a patient remained free from cancer recurrence after initial treatment. *(Numerical variable)*\n",
    "- **Relapse Free Status:** Whether the patient experienced a relapse or remained cancer-free. *(Categorical variable)*\n",
    "- **Overall Survival (Months):** Total number of months a patient survived after breast cancer diagnosis. *(Numerical variable)*\n",
    "- **Overall Survival Status:** Indicates whether the patient is alive or deceased at the time of follow-up. *(Categorical variable)*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af2e857b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient ID</th>\n",
       "      <th>Age at Diagnosis</th>\n",
       "      <th>Type of Breast Surgery</th>\n",
       "      <th>Cancer Type</th>\n",
       "      <th>Cancer Type Detailed</th>\n",
       "      <th>Cellularity</th>\n",
       "      <th>Chemotherapy</th>\n",
       "      <th>Pam50 + Claudin-low subtype</th>\n",
       "      <th>Cohort</th>\n",
       "      <th>ER status measured by IHC</th>\n",
       "      <th>ER Status</th>\n",
       "      <th>Neoplasm Histologic Grade</th>\n",
       "      <th>HER2 status measured by SNP6</th>\n",
       "      <th>HER2 Status</th>\n",
       "      <th>Tumor Other Histologic Subtype</th>\n",
       "      <th>Hormone Therapy</th>\n",
       "      <th>Inferred Menopausal State</th>\n",
       "      <th>Integrative Cluster</th>\n",
       "      <th>Primary Tumor Laterality</th>\n",
       "      <th>Lymph nodes examined positive</th>\n",
       "      <th>Mutation Count</th>\n",
       "      <th>Nottingham prognostic index</th>\n",
       "      <th>Oncotree Code</th>\n",
       "      <th>Overall Survival (Months)</th>\n",
       "      <th>Overall Survival Status</th>\n",
       "      <th>PR Status</th>\n",
       "      <th>Radio Therapy</th>\n",
       "      <th>Relapse Free Status (Months)</th>\n",
       "      <th>Relapse Free Status</th>\n",
       "      <th>Sex</th>\n",
       "      <th>3-Gene classifier subtype</th>\n",
       "      <th>Tumor Size</th>\n",
       "      <th>Tumor Stage</th>\n",
       "      <th>Patient's Vital Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MB-0000</td>\n",
       "      <td>75.65</td>\n",
       "      <td>Mastectomy</td>\n",
       "      <td>Breast Cancer</td>\n",
       "      <td>Breast Invasive Ductal Carcinoma</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>claudin-low</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Positve</td>\n",
       "      <td>Positive</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Ductal/NST</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Post</td>\n",
       "      <td>4ER+</td>\n",
       "      <td>Right</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.044</td>\n",
       "      <td>IDC</td>\n",
       "      <td>140.500000</td>\n",
       "      <td>Living</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Yes</td>\n",
       "      <td>138.65</td>\n",
       "      <td>Not Recurred</td>\n",
       "      <td>Female</td>\n",
       "      <td>ER-/HER2-</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Living</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MB-0002</td>\n",
       "      <td>43.19</td>\n",
       "      <td>Breast Conserving</td>\n",
       "      <td>Breast Cancer</td>\n",
       "      <td>Breast Invasive Ductal Carcinoma</td>\n",
       "      <td>High</td>\n",
       "      <td>No</td>\n",
       "      <td>LumA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Positve</td>\n",
       "      <td>Positive</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Ductal/NST</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Pre</td>\n",
       "      <td>4ER+</td>\n",
       "      <td>Right</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.020</td>\n",
       "      <td>IDC</td>\n",
       "      <td>84.633333</td>\n",
       "      <td>Living</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Yes</td>\n",
       "      <td>83.52</td>\n",
       "      <td>Not Recurred</td>\n",
       "      <td>Female</td>\n",
       "      <td>ER+/HER2- High Prolif</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Living</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MB-0005</td>\n",
       "      <td>48.87</td>\n",
       "      <td>Mastectomy</td>\n",
       "      <td>Breast Cancer</td>\n",
       "      <td>Breast Invasive Ductal Carcinoma</td>\n",
       "      <td>High</td>\n",
       "      <td>Yes</td>\n",
       "      <td>LumB</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Positve</td>\n",
       "      <td>Positive</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Ductal/NST</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Pre</td>\n",
       "      <td>3</td>\n",
       "      <td>Right</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.030</td>\n",
       "      <td>IDC</td>\n",
       "      <td>163.700000</td>\n",
       "      <td>Deceased</td>\n",
       "      <td>Positive</td>\n",
       "      <td>No</td>\n",
       "      <td>151.28</td>\n",
       "      <td>Recurred</td>\n",
       "      <td>Female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Died of Disease</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MB-0006</td>\n",
       "      <td>47.68</td>\n",
       "      <td>Mastectomy</td>\n",
       "      <td>Breast Cancer</td>\n",
       "      <td>Breast Mixed Ductal and Lobular Carcinoma</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Yes</td>\n",
       "      <td>LumB</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Positve</td>\n",
       "      <td>Positive</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Mixed</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Pre</td>\n",
       "      <td>9</td>\n",
       "      <td>Right</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.050</td>\n",
       "      <td>MDLC</td>\n",
       "      <td>164.933333</td>\n",
       "      <td>Living</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Yes</td>\n",
       "      <td>162.76</td>\n",
       "      <td>Not Recurred</td>\n",
       "      <td>Female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Living</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MB-0008</td>\n",
       "      <td>76.97</td>\n",
       "      <td>Mastectomy</td>\n",
       "      <td>Breast Cancer</td>\n",
       "      <td>Breast Mixed Ductal and Lobular Carcinoma</td>\n",
       "      <td>High</td>\n",
       "      <td>Yes</td>\n",
       "      <td>LumB</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Positve</td>\n",
       "      <td>Positive</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Mixed</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Post</td>\n",
       "      <td>9</td>\n",
       "      <td>Right</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.080</td>\n",
       "      <td>MDLC</td>\n",
       "      <td>41.366667</td>\n",
       "      <td>Deceased</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Yes</td>\n",
       "      <td>18.55</td>\n",
       "      <td>Recurred</td>\n",
       "      <td>Female</td>\n",
       "      <td>ER+/HER2- High Prolif</td>\n",
       "      <td>40.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Died of Disease</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Patient ID  Age at Diagnosis Type of Breast Surgery    Cancer Type                       Cancer Type Detailed  \\\n",
       "0    MB-0000             75.65             Mastectomy  Breast Cancer           Breast Invasive Ductal Carcinoma   \n",
       "1    MB-0002             43.19      Breast Conserving  Breast Cancer           Breast Invasive Ductal Carcinoma   \n",
       "2    MB-0005             48.87             Mastectomy  Breast Cancer           Breast Invasive Ductal Carcinoma   \n",
       "3    MB-0006             47.68             Mastectomy  Breast Cancer  Breast Mixed Ductal and Lobular Carcinoma   \n",
       "4    MB-0008             76.97             Mastectomy  Breast Cancer  Breast Mixed Ductal and Lobular Carcinoma   \n",
       "\n",
       "  Cellularity Chemotherapy Pam50 + Claudin-low subtype  Cohort ER status measured by IHC ER Status  \\\n",
       "0         NaN           No                 claudin-low     1.0                   Positve  Positive   \n",
       "1        High           No                        LumA     1.0                   Positve  Positive   \n",
       "2        High          Yes                        LumB     1.0                   Positve  Positive   \n",
       "3    Moderate          Yes                        LumB     1.0                   Positve  Positive   \n",
       "4        High          Yes                        LumB     1.0                   Positve  Positive   \n",
       "\n",
       "   Neoplasm Histologic Grade HER2 status measured by SNP6 HER2 Status Tumor Other Histologic Subtype Hormone Therapy  \\\n",
       "0                        3.0                      Neutral    Negative                     Ductal/NST             Yes   \n",
       "1                        3.0                      Neutral    Negative                     Ductal/NST             Yes   \n",
       "2                        2.0                      Neutral    Negative                     Ductal/NST             Yes   \n",
       "3                        2.0                      Neutral    Negative                          Mixed             Yes   \n",
       "4                        3.0                      Neutral    Negative                          Mixed             Yes   \n",
       "\n",
       "  Inferred Menopausal State Integrative Cluster Primary Tumor Laterality  Lymph nodes examined positive  \\\n",
       "0                      Post                4ER+                    Right                           10.0   \n",
       "1                       Pre                4ER+                    Right                            0.0   \n",
       "2                       Pre                   3                    Right                            1.0   \n",
       "3                       Pre                   9                    Right                            3.0   \n",
       "4                      Post                   9                    Right                            8.0   \n",
       "\n",
       "   Mutation Count  Nottingham prognostic index Oncotree Code  Overall Survival (Months) Overall Survival Status  \\\n",
       "0             NaN                        6.044           IDC                 140.500000                  Living   \n",
       "1             2.0                        4.020           IDC                  84.633333                  Living   \n",
       "2             2.0                        4.030           IDC                 163.700000                Deceased   \n",
       "3             1.0                        4.050          MDLC                 164.933333                  Living   \n",
       "4             2.0                        6.080          MDLC                  41.366667                Deceased   \n",
       "\n",
       "  PR Status Radio Therapy  Relapse Free Status (Months) Relapse Free Status     Sex 3-Gene classifier subtype  \\\n",
       "0  Negative           Yes                        138.65        Not Recurred  Female                 ER-/HER2-   \n",
       "1  Positive           Yes                         83.52        Not Recurred  Female     ER+/HER2- High Prolif   \n",
       "2  Positive            No                        151.28            Recurred  Female                       NaN   \n",
       "3  Positive           Yes                        162.76        Not Recurred  Female                       NaN   \n",
       "4  Positive           Yes                         18.55            Recurred  Female     ER+/HER2- High Prolif   \n",
       "\n",
       "   Tumor Size  Tumor Stage Patient's Vital Status  \n",
       "0        22.0          2.0                 Living  \n",
       "1        10.0          1.0                 Living  \n",
       "2        15.0          2.0        Died of Disease  \n",
       "3        25.0          2.0                 Living  \n",
       "4        40.0          2.0        Died of Disease  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3.1 Load the METABRIC Breast Cancer Dataset\n",
    "\n",
    "DATA_PATH = \"Breast Cancer METABRIC.csv\"\n",
    "\n",
    "# Check if file exists\n",
    "if not os.path.exists(DATA_PATH):\n",
    "    raise FileNotFoundError(\n",
    "        f\"Error: The data file was not found at '{DATA_PATH}'. \"\n",
    "        \"Please ensure the dataset is in the correct directory.\"\n",
    "    )\n",
    "\n",
    "df_raw = pd.read_csv(DATA_PATH)\n",
    "\n",
    "df_raw.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aaba2466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Survival Status value counts:\n",
      "Overall Survival Status\n",
      "Deceased    1144\n",
      "Living       837\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Relapse Free Status value counts:\n",
      "Relapse Free Status\n",
      "Not Recurred    1486\n",
      "Recurred        1002\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Survival variables created:\n",
      "- event_os: 1144 events out of 2509 patients (45.6%)\n",
      "- event_rfs: 1002 events out of 2388 patients\n"
     ]
    }
   ],
   "source": [
    "# 3.2 Define Survival Variables and Validate Outcomes\n",
    "\n",
    "# Standardize survival variable names\n",
    "# Primary outcome: Overall Survival (OS)\n",
    "OS_DURATION_COL = \"Overall Survival (Months)\"\n",
    "OS_STATUS_COL = \"Overall Survival Status\"\n",
    "OS_PATIENT_ID = \"Patient ID\"\n",
    "\n",
    "# Check if required columns exist\n",
    "required_cols = [OS_DURATION_COL, OS_STATUS_COL, OS_PATIENT_ID]\n",
    "missing_cols = [col for col in required_cols if col not in df_raw.columns]\n",
    "if missing_cols:\n",
    "    raise ValueError(f\"Missing required columns: {missing_cols}\")\n",
    "\n",
    "# Create standardized survival variables\n",
    "df = df_raw.copy()\n",
    "\n",
    "# Convert survival status to binary event indicator\n",
    "# \"Deceased\" = 1 (event occurred), \"Living\" = 0 (censored)\n",
    "print(\"Overall Survival Status value counts:\")\n",
    "print(df[OS_STATUS_COL].value_counts())\n",
    "\n",
    "# Create event indicator\n",
    "df[\"event_os\"] = (df[OS_STATUS_COL] == \"Deceased\").astype(int)\n",
    "df[\"duration_os\"] = df[OS_DURATION_COL].astype(float)\n",
    "\n",
    "# Secondary outcome: Relapse-Free Survival (if available)\n",
    "if \"Relapse Free Status\" in df.columns and \"Relapse Free Status (Months)\" in df.columns:\n",
    "    RFS_STATUS_COL = \"Relapse Free Status\"\n",
    "    RFS_DURATION_COL = \"Relapse Free Status (Months)\"\n",
    "    df[\"event_rfs\"] = (df[RFS_STATUS_COL] == \"Recurred\").astype(int)\n",
    "    df[\"duration_rfs\"] = df[RFS_DURATION_COL].astype(float)\n",
    "    print(\"\\nRelapse Free Status value counts:\")\n",
    "    print(df[RFS_STATUS_COL].value_counts())\n",
    "\n",
    "print(f\"\\nSurvival variables created:\")\n",
    "print(f\"- event_os: {df['event_os'].sum()} events out of {len(df)} patients ({df['event_os'].mean()*100:.1f}%)\")\n",
    "if \"event_rfs\" in df.columns:\n",
    "    print(f\"- event_rfs: {df['event_rfs'].sum()} events out of {df['duration_rfs'].notna().sum()} patients\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f22d225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing rows with missing survival outcomes...\n",
      "  Removed 528 rows with missing outcomes\n",
      "  Removed 1 rows with non-positive survival times\n",
      "\n",
      "Final cohort size: 1980 patients\n",
      "Event rate: 57.8% (1144 events)\n",
      "\n",
      "============================================================\n",
      "SURVIVAL OUTCOME SUMMARY\n",
      "============================================================\n",
      "Duration (months) - Median: 116.5, Mean: 125.3\n",
      "Duration (months) - Min: 0.1, Max: 355.2\n",
      "IQR: [60.9, 185.1]\n",
      "Events: 1144 (57.8%)\n",
      "Censored: 836 (42.2%)\n"
     ]
    }
   ],
   "source": [
    "# 3.3 Data Cleaning and Cohort Definition\n",
    "\n",
    "# Keep track of original size\n",
    "n_original = len(df)\n",
    "\n",
    "# Remove rows with missing survival outcomes (cannot analyze without outcome)\n",
    "print(\"Removing rows with missing survival outcomes...\")\n",
    "df = df.dropna(subset=[\"duration_os\", \"event_os\"]).copy()\n",
    "print(f\"  Removed {n_original - len(df)} rows with missing outcomes\")\n",
    "\n",
    "# Remove rows with non-positive survival times (must be > 0)\n",
    "n_before = len(df)\n",
    "df = df[df[\"duration_os\"] > 0].copy()\n",
    "if len(df) < n_before:\n",
    "    print(f\"  Removed {n_before - len(df)} rows with non-positive survival times\")\n",
    "\n",
    "# Validate event indicator is binary\n",
    "assert df[\"event_os\"].isin([0, 1]).all(), \"Event indicator must be 0 or 1\"\n",
    "\n",
    "# Check for duplicate patient IDs\n",
    "n_duplicates = df[OS_PATIENT_ID].duplicated().sum()\n",
    "if n_duplicates > 0:\n",
    "    print(f\"Warning: Found {n_duplicates} duplicate patient IDs\")\n",
    "    df = df.drop_duplicates(subset=[OS_PATIENT_ID], keep='first')\n",
    "    print(f\"  Kept first occurrence for each patient\")\n",
    "\n",
    "print(f\"\\nFinal cohort size: {len(df)} patients\")\n",
    "print(f\"Event rate: {df['event_os'].mean()*100:.1f}% ({df['event_os'].sum()} events)\")\n",
    "\n",
    "# Display summary statistics\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SURVIVAL OUTCOME SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Duration (months) - Median: {df['duration_os'].median():.1f}, Mean: {df['duration_os'].mean():.1f}\")\n",
    "print(f\"Duration (months) - Min: {df['duration_os'].min():.1f}, Max: {df['duration_os'].max():.1f}\")\n",
    "print(f\"IQR: [{df['duration_os'].quantile(0.25):.1f}, {df['duration_os'].quantile(0.75):.1f}]\")\n",
    "print(f\"Events: {df['event_os'].sum()} ({df['event_os'].mean()*100:.1f}%)\")\n",
    "print(f\"Censored: {(df['event_os']==0).sum()} ({(df['event_os']==0).mean()*100:.1f}%)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313335af",
   "metadata": {},
   "source": [
    "## 4. Single Consolidated Pipeline with Leakage Controls and Group-Aware Split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90442de",
   "metadata": {},
   "source": [
    "### 4.1 Leakage Control Strategy\n",
    "\n",
    "**Leakage controls implemented:**\n",
    "\n",
    "\n",
    "**Variables to EXCLUDE:**\n",
    "- `Patient ID` (identifier, may use for grouping)\n",
    "- `Overall Survival (Months)` (direct outcome)\n",
    "- `Overall Survival Status` (direct outcome)\n",
    "- `Relapse Free Status (Months)` (if using OS as outcome)\n",
    "- `Relapse Free Status` (if using OS as outcome)\n",
    "- `Patient's Vital Status` (likely redundant with OS status)\n",
    "- Any variables derived from outcomes or measured post-treatment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c01a8d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns to exclude from features (leakage control):\n",
      "\n",
      "Original outcome columns:\n",
      "  - Overall Survival (Months)\n",
      "  - Overall Survival Status\n",
      "  - Relapse Free Status (Months)\n",
      "  - Relapse Free Status\n",
      "  - Patient's Vital Status\n",
      "\n",
      "Standardized outcome columns (created in cell 7):\n",
      "  - duration_os\n",
      "  - duration_rfs\n",
      "  - event_os\n",
      "  - event_rfs\n",
      "\n",
      "Identifier column:\n",
      "  - Patient ID\n",
      "\n",
      "✓ Removed 10 outcome/identifier columns from features\n",
      "\n",
      "Feature matrix shape: (1980, 28)\n",
      "Outcome matrix shape: (1980, 2)\n"
     ]
    }
   ],
   "source": [
    "# 4.1 Define Columns to Drop (Leakage Control)\n",
    "\n",
    "# Columns that directly contain outcome information (LEAKAGE)\n",
    "# Original column names from the dataset\n",
    "OUTCOME_COLS = [\n",
    "    \"Overall Survival (Months)\",\n",
    "    \"Overall Survival Status\", \n",
    "    \"Relapse Free Status (Months)\",\n",
    "    \"Relapse Free Status\",\n",
    "    \"Patient's Vital Status\"\n",
    "]\n",
    "\n",
    "# Standardized outcome columns we created (also need to be excluded!)\n",
    "STANDARDIZED_OUTCOME_COLS = [\n",
    "    \"duration_os\",      # Duration for Overall Survival - OUTCOME!\n",
    "    \"duration_rfs\",     # Duration for Relapse-Free Survival - OUTCOME!\n",
    "    \"event_os\",         # Event indicator for OS - OUTCOME! (but we keep it in y)\n",
    "    \"event_rfs\"         # Event indicator for RFS - OUTCOME!\n",
    "]\n",
    "\n",
    "# Identifier column (keep for grouping but exclude from features)\n",
    "ID_COL = \"Patient ID\"\n",
    "\n",
    "# Combine all columns to drop (original + standardized outcome columns)\n",
    "cols_to_drop = []\n",
    "cols_to_drop.extend([col for col in OUTCOME_COLS + [ID_COL] if col in df.columns])\n",
    "cols_to_drop.extend([col for col in STANDARDIZED_OUTCOME_COLS if col in df.columns])\n",
    "\n",
    "print(\"Columns to exclude from features (leakage control):\")\n",
    "print(\"\\nOriginal outcome columns:\")\n",
    "for col in OUTCOME_COLS:\n",
    "    if col in df.columns:\n",
    "        print(f\"  - {col}\")\n",
    "\n",
    "print(\"\\nStandardized outcome columns (created in cell 7):\")\n",
    "for col in STANDARDIZED_OUTCOME_COLS:\n",
    "    if col in df.columns:\n",
    "        print(f\"  - {col}\")\n",
    "\n",
    "if ID_COL in df.columns:\n",
    "    print(f\"\\nIdentifier column:\")\n",
    "    print(f\"  - {ID_COL}\")\n",
    "\n",
    "# Create X (features) and y (outcome) dataframes\n",
    "# Note: event_os and duration_os are kept in y but removed from X\n",
    "X = df.drop(columns=cols_to_drop, errors='ignore').copy()\n",
    "y = df[[\"duration_os\", \"event_os\"]].copy()\n",
    "\n",
    "print(f\"\\n✓ Removed {len(cols_to_drop)} outcome/identifier columns from features\")\n",
    "\n",
    "# Also store patient IDs for group-aware splitting if needed\n",
    "patient_ids = df[ID_COL].values if ID_COL in df.columns else None\n",
    "\n",
    "print(f\"\\nFeature matrix shape: {X.shape}\")\n",
    "print(f\"Outcome matrix shape: {y.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72bb56de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split sizes train 1188 val 396 test 396\n",
      "\n",
      "============================================================\n",
      "SPLIT SUMMARY\n",
      "============================================================\n",
      "Train set:      1188 samples ( 60.0%)\n",
      "Validation set:  396 samples ( 20.0%)\n",
      "Test set:        396 samples ( 20.0%)\n",
      "Total:          1980 samples\n",
      "\n",
      "============================================================\n",
      "EVENT RATES ACROSS SPLITS (should be similar)\n",
      "============================================================\n",
      "Train:       57.7% (686 events)\n",
      "Validation:  57.8% (229 events)\n",
      "Test:        57.8% (229 events)\n"
     ]
    }
   ],
   "source": [
    "# 4.2 Create stratified train, validation, and test splits re-used across all models\n",
    "\n",
    "def make_splits(X: pd.DataFrame, y: pd.Series, seed: int = 42):\n",
    "    \"\"\"\n",
    "    Create stratified train/validation/test splits (60/20/20).\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    X : pd.DataFrame\n",
    "        Feature matrix\n",
    "    y : pd.Series\n",
    "        Outcome variable for stratification (e.g., event indicator)\n",
    "    seed : int\n",
    "        Random seed for reproducibility\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    idx_train, idx_val, idx_test : array-like\n",
    "        Indices for train, validation, and test sets\n",
    "    \"\"\"\n",
    "    # First split off test 20 percent\n",
    "    sss1 = StratifiedShuffleSplit(n_splits=1, test_size=0.20, random_state=seed)\n",
    "    train_val_idx, test_idx = next(sss1.split(X, y))\n",
    "    X_train_val, X_test = X.iloc[train_val_idx], X.iloc[test_idx]\n",
    "    y_train_val, y_test = y.iloc[train_val_idx], y.iloc[test_idx]\n",
    "\n",
    "    # Split train vs validation 75:25 within the remaining 80 percent to yield 60:20:20 overall\n",
    "    sss2 = StratifiedShuffleSplit(n_splits=1, test_size=0.25, random_state=seed)\n",
    "    train_idx, val_idx = next(sss2.split(X_train_val, y_train_val))\n",
    "\n",
    "    idx_train = X_train_val.index[train_idx]\n",
    "    idx_val = X_train_val.index[val_idx]\n",
    "    idx_test = X_test.index\n",
    "\n",
    "    return idx_train, idx_val, idx_test\n",
    "\n",
    "# Create splits using event_os for stratification\n",
    "idx_train, idx_val, idx_test = make_splits(X, y[\"event_os\"], seed=SEED)\n",
    "\n",
    "print(\"Split sizes\",\n",
    "      \"train\", len(idx_train),\n",
    "      \"val\", len(idx_val),\n",
    "      \"test\", len(idx_test))\n",
    "\n",
    "# Materialize split datasets\n",
    "X_train, X_val, X_test = X.loc[idx_train], X.loc[idx_val], X.loc[idx_test]\n",
    "y_train, y_val, y_test = y.loc[idx_train], y.loc[idx_val], y.loc[idx_test]\n",
    "\n",
    "# Display split information\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SPLIT SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Train set:      {len(X_train):4d} samples ({len(X_train)/len(X)*100:5.1f}%)\")\n",
    "print(f\"Validation set: {len(X_val):4d} samples ({len(X_val)/len(X)*100:5.1f}%)\")\n",
    "print(f\"Test set:       {len(X_test):4d} samples ({len(X_test)/len(X)*100:5.1f}%)\")\n",
    "print(f\"Total:          {len(X):4d} samples\")\n",
    "\n",
    "# Check event rates across splits\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EVENT RATES ACROSS SPLITS (should be similar)\")\n",
    "print(\"=\"*60)\n",
    "event_rate_train = y_train[\"event_os\"].mean()\n",
    "event_rate_val = y_val[\"event_os\"].mean()\n",
    "event_rate_test = y_test[\"event_os\"].mean()\n",
    "print(f\"Train:      {event_rate_train*100:5.1f}% ({y_train['event_os'].sum():3d} events)\")\n",
    "print(f\"Validation: {event_rate_val*100:5.1f}% ({y_val['event_os'].sum():3d} events)\")\n",
    "print(f\"Test:       {event_rate_test*100:5.1f}% ({y_test['event_os'].sum():3d} events)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd276859",
   "metadata": {},
   "source": [
    "### 4.3 Feature Type Detection and Preprocessing Pipeline\n",
    "\n",
    "1. **Feature Type Detection**\n",
    "   - Automatically identifies which features are categorical (discrete categories) vs numeric (continuous numbers)\n",
    "   - Categorical features: text/object types or integers with few unique values\n",
    "   - Numeric features: continuous variables like age, tumor size, mutation count\n",
    "\n",
    "2. **Preprocessing Pipeline Construction**\n",
    "   - Creates separate transformation pipelines for categorical and numeric features\n",
    "   - **Numeric pipeline**: Imputes missing values with median → Standardizes (z-score normalization)\n",
    "   - **Categorical pipeline**: Imputes missing values with most frequent category → One-hot encodes\n",
    "\n",
    "3. **Leakage Prevention**\n",
    "   - Pipeline is fitted **ONLY** on training data\n",
    "   - Validation and test sets are transformed using parameters learned from training\n",
    "   - This ensures realistic performance estimates and prevents data leakage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d099c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "FEATURE TYPE DETECTION\n",
      "============================================================\n",
      "Categorical features: 23\n",
      "Numeric features:     5\n",
      "\n",
      "Categorical features (first 10):\n",
      "  Type of Breast Surgery                   -   2 unique values,   16 missing\n",
      "  Cancer Type                              -   2 unique values,    0 missing\n",
      "  Cancer Type Detailed                     -   8 unique values,    0 missing\n",
      "  Cellularity                              -   3 unique values,   36 missing\n",
      "  Chemotherapy                             -   2 unique values,    1 missing\n",
      "  Pam50 + Claudin-low subtype              -   7 unique values,    1 missing\n",
      "  Cohort                                   -   5 unique values,    0 missing\n",
      "  ER status measured by IHC                -   2 unique values,   24 missing\n",
      "  ER Status                                -   2 unique values,    0 missing\n",
      "  Neoplasm Histologic Grade                -   3 unique values,   50 missing\n",
      "\n",
      "Numeric features (first 10):\n",
      "  Age at Diagnosis                         -    0 missing, mean=60.99\n",
      "  Lymph nodes examined positive            -   46 missing, mean=2.02\n",
      "  Mutation Count                           -   75 missing, mean=5.59\n",
      "  Nottingham prognostic index              -    1 missing, mean=4.02\n",
      "  Tumor Size                               -   16 missing, mean=26.50\n",
      "\n",
      "============================================================\n",
      "PREPROCESSING PIPELINE BUILT\n",
      "============================================================\n",
      "\n",
      "Pipeline components:\n",
      "  1. Numeric features:\n",
      "     - Median imputation\n",
      "     - Standardization (z-score)\n",
      "     - 5 features\n",
      "\n",
      "  2. Categorical features:\n",
      "     - Most frequent imputation\n",
      "     - One-hot encoding\n",
      "     - 23 features\n",
      "\n",
      "============================================================\n",
      "FITTING PREPROCESSOR ON TRAINING DATA\n",
      "============================================================\n",
      "\n",
      "Transforming datasets...\n",
      "\n",
      "Transformed feature dimensions:\n",
      "  Train:      (1188, 83)\n",
      "  Validation: (396, 83)\n",
      "  Test:       (396, 83)\n",
      "\n",
      "============================================================\n",
      "TRANSFORMED DATA SUMMARY\n",
      "============================================================\n",
      "Transformed DataFrames created:\n",
      "  Xt_train: (1188, 83)\n",
      "  Xt_val:   (396, 83)\n",
      "  Xt_test:  (396, 83)\n",
      "\n",
      "============================================================\n",
      "LEAKAGE CHECK: Verifying no outcome columns in features\n",
      "============================================================\n",
      "✓ No leakage detected - all outcome-related columns properly excluded\n",
      "✓ All leakage checks passed!\n",
      "\n",
      "✓ Preprocessing pipeline completed successfully!\n",
      "  All transformations were fit on training data only\n",
      "  Validation and test sets transformed using training fit parameters\n",
      "  This prevents data leakage from validation/test into training\n"
     ]
    }
   ],
   "source": [
    "# 4.3 Feature Type Detection and Preprocessing Pipeline\n",
    "\n",
    "def detect_feature_types(X):\n",
    "    # Identify categorical columns (object type or with few unique values)\n",
    "    cat_cols = []\n",
    "    num_cols = []\n",
    "    \n",
    "    for col in X.columns:\n",
    "        if X[col].dtype == 'object':\n",
    "            cat_cols.append(col)\n",
    "        elif X[col].dtype in ['int64', 'float64']:\n",
    "            # Consider low-cardinality integer columns as categorical if they have few unique values\n",
    "            n_unique = X[col].nunique()\n",
    "            if n_unique <= 10 and n_unique < len(X) * 0.05:  # Less than 5% unique values\n",
    "                cat_cols.append(col)\n",
    "            else:\n",
    "                num_cols.append(col)\n",
    "        else:\n",
    "            # Default to numeric for other types\n",
    "            num_cols.append(col)\n",
    "    \n",
    "    return cat_cols, num_cols\n",
    "\n",
    "\n",
    "# Detect feature types from training data\n",
    "cat_cols, num_cols = detect_feature_types(X_train)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"FEATURE TYPE DETECTION\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Categorical features: {len(cat_cols)}\")\n",
    "print(f\"Numeric features:     {len(num_cols)}\")\n",
    "\n",
    "if len(cat_cols) > 0:\n",
    "    print(f\"\\nCategorical features (first 10):\")\n",
    "    for col in cat_cols[:10]:\n",
    "        n_unique = X_train[col].nunique()\n",
    "        n_missing = X_train[col].isnull().sum()\n",
    "        print(f\"  {col:40s} - {n_unique:3d} unique values, {n_missing:4d} missing\")\n",
    "\n",
    "if len(num_cols) > 0:\n",
    "    print(f\"\\nNumeric features (first 10):\")\n",
    "    for col in num_cols[:10]:\n",
    "        n_missing = X_train[col].isnull().sum()\n",
    "        mean_val = X_train[col].mean()\n",
    "        print(f\"  {col:40s} - {n_missing:4d} missing, mean={mean_val:.2f}\")\n",
    "\n",
    "# 4.5 Build Consolidated Preprocessing Pipeline\n",
    "\n",
    "# Numeric feature pipeline\n",
    "# - Impute missing values with median (fit on train only)\n",
    "# - Standardize to zero mean and unit variance (fit on train only)\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Categorical feature pipeline\n",
    "# - Impute missing values with most frequent category (fit on train only)\n",
    "# - One-hot encode (fit on train only, ignore unknown categories at transform time)\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(drop='if_binary', handle_unknown='ignore', sparse_output=False))\n",
    "])\n",
    "\n",
    "# Combined preprocessor\n",
    "# This ensures all transformations are fit on training data only\n",
    "# and applied consistently to validation and test sets\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, num_cols),\n",
    "        ('cat', categorical_transformer, cat_cols)\n",
    "    ],\n",
    "    remainder='drop',  # Drop any columns not explicitly handled\n",
    "    verbose_feature_names_out=False  # Keep original feature names where possible\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PREPROCESSING PIPELINE BUILT\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nPipeline components:\")\n",
    "print(\"  1. Numeric features:\")\n",
    "print(\"     - Median imputation\")\n",
    "print(\"     - Standardization (z-score)\")\n",
    "print(f\"     - {len(num_cols)} features\")\n",
    "print(\"\\n  2. Categorical features:\")\n",
    "print(\"     - Most frequent imputation\")\n",
    "print(\"     - One-hot encoding\")\n",
    "print(f\"     - {len(cat_cols)} features\")\n",
    "\n",
    "# Fit preprocessor on training data only\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FITTING PREPROCESSOR ON TRAINING DATA\")\n",
    "print(\"=\"*60)\n",
    "preprocessor.fit(X_train)\n",
    "\n",
    "# Transform all splits\n",
    "print(\"\\nTransforming datasets...\")\n",
    "X_train_transformed = preprocessor.transform(X_train)\n",
    "X_val_transformed = preprocessor.transform(X_val)\n",
    "X_test_transformed = preprocessor.transform(X_test)\n",
    "\n",
    "print(f\"\\nTransformed feature dimensions:\")\n",
    "print(f\"  Train:      {X_train_transformed.shape}\")\n",
    "print(f\"  Validation: {X_val_transformed.shape}\")\n",
    "print(f\"  Test:       {X_test_transformed.shape}\")\n",
    "\n",
    "# Create transformed DataFrames for convenience\n",
    "# Convert to DataFrame if not already (when set_config is used)\n",
    "if hasattr(X_train_transformed, 'columns'):\n",
    "    Xt_train = X_train_transformed\n",
    "    Xt_val = X_val_transformed\n",
    "    Xt_test = X_test_transformed\n",
    "else:\n",
    "    # Convert numpy arrays to DataFrames with feature names\n",
    "    try:\n",
    "        feature_names = preprocessor.get_feature_names_out()\n",
    "        Xt_train = pd.DataFrame(X_train_transformed, \n",
    "                                index=X_train.index, \n",
    "                                columns=feature_names)\n",
    "        Xt_val = pd.DataFrame(X_val_transformed, \n",
    "                             index=X_val.index, \n",
    "                             columns=feature_names)\n",
    "        Xt_test = pd.DataFrame(X_test_transformed, \n",
    "                               index=X_test.index, \n",
    "                               columns=feature_names)\n",
    "    except:\n",
    "        # Fallback if feature names not available\n",
    "        Xt_train = pd.DataFrame(X_train_transformed, index=X_train.index)\n",
    "        Xt_val = pd.DataFrame(X_val_transformed, index=X_val.index)\n",
    "        Xt_test = pd.DataFrame(X_test_transformed, index=X_test.index)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRANSFORMED DATA SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Transformed DataFrames created:\")\n",
    "print(f\"  Xt_train: {Xt_train.shape}\")\n",
    "print(f\"  Xt_val:   {Xt_val.shape}\")\n",
    "print(f\"  Xt_test:  {Xt_test.shape}\")\n",
    "\n",
    "# Quick leakage sanity check: confirm no outcome columns survived\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"LEAKAGE CHECK: Verifying no outcome columns in features\")\n",
    "print(\"=\"*60)\n",
    "leakage_terms = [\n",
    "    \"overall survival\",\n",
    "    \"relapse free status\", \n",
    "    \"patient's vital status\",\n",
    "    \"event_os\",\n",
    "    \"duration_os\",\n",
    "    \"patient id\"\n",
    "]\n",
    "\n",
    "leakage_found = []\n",
    "for term in leakage_terms:\n",
    "    matching_cols = [c for c in Xt_train.columns if term.lower() in str(c).lower()]\n",
    "    if matching_cols:\n",
    "        leakage_found.extend(matching_cols)\n",
    "\n",
    "if leakage_found:\n",
    "    print(f\"⚠ WARNING: Found potential leakage columns: {leakage_found}\")\n",
    "else:\n",
    "    print(\"✓ No leakage detected - all outcome-related columns properly excluded\")\n",
    "\n",
    "# Additional assertions\n",
    "assert not any(\"overall survival\" in str(c).lower() for c in Xt_train.columns), \\\n",
    "    \"Leakage detected: Overall Survival column found in features\"\n",
    "assert not any(\"relapse free status\" in str(c).lower() for c in Xt_train.columns), \\\n",
    "    \"Leakage detected: Relapse Free Status column found in features\"\n",
    "assert not any(\"patient id\" in str(c).lower() for c in Xt_train.columns), \\\n",
    "    \"Leakage detected: Patient ID column found in features\"\n",
    "\n",
    "print(\"✓ All leakage checks passed!\")\n",
    "print(\"\\n✓ Preprocessing pipeline completed successfully!\")\n",
    "print(\"  All transformations were fit on training data only\")\n",
    "print(\"  Validation and test sets transformed using training fit parameters\")\n",
    "print(\"  This prevents data leakage from validation/test into training\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf25d9b",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ad3e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b252e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a039b51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4078b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6a4830",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e83f7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8303da42",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf66369c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
